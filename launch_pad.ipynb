{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15c117a-2810-456a-b956-86d2985385d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "970c0f09-b321-4c9f-b676-e3d6765c9e7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_table_name=\"ref_diag\"\n",
    "src_database=\"conformednpii\"\n",
    "tgt_db_typ=\"mysql\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdc1f194-0163-4234-9eea-c75e8973e728",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01610e47-318a-44d6-acd2-ddc13617d9e7",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_current_notebook_path():\n",
    "    notebook_path = dbutils.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "    return notebook_path\n",
    "\n",
    "def get_environment_from_notebook_path():\n",
    "    #note_book_path = get_current_notebook_path()\n",
    "    #main_logger.info(f\"Notebook path :{note_book_path}\")\n",
    "    if  spark.conf.get(\"spark.databricks.clusterUsageTags.clusterOwnerOrgId\")=='4022166418081681':\n",
    "        return 'PT'\n",
    "    elif spark.conf.get(\"spark.databricks.clusterUsageTags.clusterOwnerOrgId\")=='add production id':\n",
    "        return 'prod'\n",
    "\n",
    "def get_user_mysql_cred(mysql_env,secret_mgr_scope='ds-edw-prod'):\n",
    "    if mysql_env.lower() in ['pt','prod']:\n",
    "        mysql_ip=None #dbutils.secrets.get(scope=secret_mgr_scope, key='HOST_NAME')\n",
    "        mysql_port=None #dbutils.secrets.get(scope=secret_mgr_scope, key='HOST_PORT')\n",
    "        musql_username=None #dbutils.secrets.get(scope=secret_mgr_scope, key='USERNAME')\n",
    "        mysql_password=None #dbutils.secrets.get(scope=secret_mgr_scope, key='PASSWORD')\n",
    "        return (mysql_ip,mysql_port,musql_username,mysql_password)\n",
    "    else:\n",
    "        raise Exception(f\"Invalid environment for mysql user credentials {mysql_env}\")\n",
    "\n",
    "def get_redshift_user_cred(redshift_env,secret_mgr_scope):\n",
    "    if redshift_env.lower() in ['prod']:\n",
    "        redshift_ip_user = None #dbutils.secrets.get(scope=secret_mgr_scope, key=\"redshift_talend_username\")\n",
    "        redshift_password = None #dbutils.secrets.get(scope=secret_mgr_scope, key=\"redshift_talend_password\")\n",
    "        return redshift_ip_user,redshift_password\n",
    "    else:\n",
    "        raise Exception(f\"Invalid environment for redshift user credentials {mysql_env}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "128e66d4-2c40-4a1e-b2d1-6ec4188402a9",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import entry_point\n",
    "import importlib\n",
    "importlib.reload(entry_point)\n",
    "environment = get_environment_from_notebook_path()\n",
    "\n",
    "mysql_ip,mysql_port,mysql_username,mysql_password = get_user_mysql_cred(mysql_env=environment,secret_mgr_scope='ds-edw-prod')\n",
    "redshift_user,redshift_pass = get_redshift_user_cred(redshift_env='prod',secret_mgr_scope='ds-edw-prod')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72da289d-9d0c-40de-8512-4a37a75ff173",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df=spark.table(\"udf_internal.udf_to_rdbms_sync\").where(f\"src_tbl='{src_table_name}'\").select(\"udf_to_rdbms_sync_key\",\"src_db\",\"src_tbl\",\"tgt_db_typ\",\"tgt_db\",\"tgt_tbl\",\"merge_keys\")\n",
    "\n",
    "assert df.count() > 0, \"No records found in udf_internal.udf_to_rdbms_sync\"\n",
    "\n",
    "# check last successful log entry and get watermark value\n",
    "\n",
    "\n",
    "for row in df.collect():\n",
    "    src_db=row[\"src_db\"]\n",
    "    src_tbl=row[\"src_tbl\"]\n",
    "    tgt_db_typ=row[\"tgt_db_typ\"]\n",
    "    tgt_db=row[\"tgt_db\"]\n",
    "    tgt_tbl=row[\"tgt_tbl\"]\n",
    "    merge_keys=row[\"merge_keys\"]\n",
    "    udf_to_rdbms_sync_key=row[\"udf_to_rdbms_sync_key\"]\n",
    "    \n",
    "    watermark_value = spark.table(\"udf_internal.udf_to_rdbms_sync_log\").where(f\"udf_to_rdbms_sync_key='{udf_to_rdbms_sync_key}'\").where(\"current_status='success'\").agg({\"watermark_value\": \"max\"}).collect()[0][0]\n",
    "\n",
    "\n",
    "    filter_condition= \"1=1\" \n",
    "    if watermark_value:\n",
    "        filter_condition=f\"udf_updated_dt >= '{watermark_value}'\"\n",
    "    rows=spark.read.format(\"delta\").load(f\"/Volumes/ptudfnpii/npii/{src_db}/reference/{tgt_tbl}/\").where(filter_condition).count()\n",
    "    sql_conn= (mysql_ip,mysql_port,mysql_username,mysql_password,redshift_user,redshift_pass)\n",
    "    print(len(sql_conn))\n",
    "    master_obj= entry_point.start_dbks_dms(row,sql_conn)\n",
    "  \n",
    "                                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1597699502190038,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "launch_pad",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
